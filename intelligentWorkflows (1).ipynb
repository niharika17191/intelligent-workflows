{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.rdd.RDD\n",
    "import com.databricks.spark.csv\n",
    "import org.apache.spark.mllib.feature.{StandardScaler, Normalizer}\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.mllib.clustering.{KMeans, KMeansModel}\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.hive.HiveContext\n",
    "import breeze.linalg.DenseVector\n",
    "import breeze.linalg.DenseMatrix\n",
    "import scala.collection._\n",
    "import play.api.libs.json._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var credentials_1 = scala.collection.mutable.HashMap[String, String](\n",
    "  \"auth_url\"->\"https://identity.open.softlayer.com\",\n",
    "  \"project\"->\"object_storage_7115a8c7_5ba1_47b4_84ad_60d394b80e0d\",\n",
    "  \"project_id\"->\"d9baeb325dc54f4295d956b82f06a47f\",\n",
    "  \"region\"->\"dallas\",\n",
    "  \"user_id\"->\"4b2349419a524e65b0aa0c5ff155771c\",\n",
    "  \"domain_id\"->\"494f75a1a8aa4655b93ac9e88be244a4\",\n",
    "  \"domain_name\"->\"1055881\",\n",
    "  \"username\"->\"admin_5880b7404a7aa61ca5826c7c8c569f27f8d377cf\",\n",
    "  \"password\"->\"\"\"hH)3(t8m1kyOdAU*\"\"\",\n",
    "  \"filename\"->\"testData4.csv\",\n",
    "  \"container\"->\"notebooks\",\n",
    "  \"tenantId\"->\"s1b2-40518d39c0c1ed-0c1e95d7674b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var credentials_2 = scala.collection.mutable.HashMap[String, String](\n",
    "  \"auth_url\"->\"https://identity.open.softlayer.com\",\n",
    "  \"project\"->\"object_storage_7115a8c7_5ba1_47b4_84ad_60d394b80e0d\",\n",
    "  \"project_id\"->\"d9baeb325dc54f4295d956b82f06a47f\",\n",
    "  \"region\"->\"dallas\",\n",
    "  \"user_id\"->\"4b2349419a524e65b0aa0c5ff155771c\",\n",
    "  \"domain_id\"->\"494f75a1a8aa4655b93ac9e88be244a4\",\n",
    "  \"domain_name\"->\"1055881\",\n",
    "  \"username\"->\"admin_5880b7404a7aa61ca5826c7c8c569f27f8d377cf\",\n",
    "  \"password\"->\"\"\"hH)3(t8m1kyOdAU*\"\"\",\n",
    "  \"filename\"->\"testData3.csv\",\n",
    "  \"container\"->\"notebooks\",\n",
    "  \"tenantId\"->\"s1b2-40518d39c0c1ed-0c1e95d7674b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials_1(\"name\")=\"keystone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setHadoopConfig(name: String, tenant: String, url: String, username: String, password: String, region: String) = {\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.auth.url\",url+\"/v3/auth/tokens\")\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.auth.endpoint.prefix\",\"endpoints\")\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.tenant\",tenant)\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.username\",username)\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.password\",password)\n",
    "    sc.hadoopConfiguration.setInt(f\"fs.swift.service.$name.http.port\",8080)\n",
    "    sc.hadoopConfiguration.set(f\"fs.swift.service.$name.region\",region)\n",
    "    sc.hadoopConfiguration.setBoolean(f\"fs.swift.service.$name.public\",true)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setHadoopConfig(credentials_1(\"name\"), credentials_1(\"project_id\"), credentials_1(\"auth_url\"), credentials_1(\"user_id\"), credentials_1(\"password\"), credentials_1(\"region\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "//val hqlContext = new HiveContext(sc)\n",
    "//val sqlContext = new SQLContext(sc)\n",
    "//val hqlContext = new org.apache.spark.sql.hive.HiveContext(sc) \n",
    "import sqlContext.implicits._\n",
    "import sqlContext._\n",
    "import org.apache.spark.sql._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case class Task(issueName: String, source: String, userName: String, timeInDays: Integer, complexities: Integer, dayOfWeek: Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var data = sc.textFile(\"swift://notebooks.keystone/testData4.csv\")\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val allSplit = data.map(line => line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val allData = allSplit.map(p => Task(p(0), p(1), p(2), p(3).toInt, p(4).toInt, p(5).toInt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val allDF = allData.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[7] at map at <console>:61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rowsRDD = allDF.rdd.map(r => (r.getString(0), r.getString(1), r.getString(2), r.getInt(3), r.getInt(4), r.getInt(5)))\n",
    "\n",
    "rowsRDD.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val vectors = allDF.rdd.map(r => Vectors.dense( r.getInt(3), r.getInt(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[8] at map at <console>:61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allDF.registerTempTable(\"sfpd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "val userData = sqlContext.sql(\"SELECT userName, COUNT(userName) AS frequency FROM sfpd group by userName\").collect()\n",
    "val noOfClusters = userData.length\n",
    "println(noOfClusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val kMeansModel = KMeans.train(vectors, noOfClusters, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.875,1.0]\n",
      "[6.0,1.0]\n",
      "[8.0,1.0]\n"
     ]
    }
   ],
   "source": [
    "val result = kMeansModel.clusterCenters.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val siic1 = kMeansModel.computeCost(vectors)\n",
    "val indices = kMeansModel.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val predictions = rowsRDD.map{r => (r._3, kMeansModel.predict(Vectors.dense(r._4, r._5) ))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val predDF = predictions.toDF(\"userName\", \"CLUSTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[userName: string, CLUSTER: int]\n"
     ]
    }
   ],
   "source": [
    "println(predDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val t = allDF.join(predDF, \"userName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+----------+------------+---------+-------+\n",
      "|userName|issueName| source|timeInDays|complexities|dayOfWeek|CLUSTER|\n",
      "+--------+---------+-------+----------+------------+---------+-------+\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task1|source1|         2|           1|        1|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "|   User1|    Task2|source1|         2|           1|        2|      0|\n",
      "+--------+---------+-------+----------+------------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.filter(\"CLUSTER = 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.filter(\"CLUSTER = 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.filter(\"CLUSTER = 0\").show()\n",
    "t.filter(\"CLUSTER = 1\").show()\n",
    "t.filter(\"CLUSTER = 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.filter(\"CLUSTER = 0\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val vectors1 = allDF.rdd.map(r => Vectors.dense( r.getInt(4), r.getInt(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[61] at map at <console>:61"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors1.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "val DataOfDays = sqlContext.sql(\"SELECT DISTINCT dayOfWeek FROM sfpd group by dayOfWeek\").collect()\n",
    "val noOfClusters1 = DataOfDays.length\n",
    "println(noOfClusters1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val kMeansModel1 = KMeans.train(vectors1, noOfClusters1, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.875,1.0]\n",
      "[6.0,1.0]\n",
      "[8.0,1.0]\n"
     ]
    }
   ],
   "source": [
    "val result = kMeansModel.clusterCenters.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[1.0,1.0]\n",
      "[1.0,2.0]\n"
     ]
    }
   ],
   "source": [
    "val vectors1 = allDF.rdd.map(r => Vectors.dense( r.getInt(4), r.getInt(5)))\n",
    "vectors1.cache()\n",
    "val DataOfDays = sqlContext.sql(\"SELECT DISTINCT dayOfWeek FROM sfpd group by dayOfWeek\").collect()\n",
    "val noOfClusters1 = DataOfDays.length\n",
    "println(noOfClusters1)\n",
    "val kMeansModel1 = KMeans.train(vectors1, noOfClusters1, 15000)\n",
    "val result = kMeansModel1.clusterCenters.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[530] at map at <console>:71\n"
     ]
    }
   ],
   "source": [
    "val predictions1 = rowsRDD.map{r => (r._1, kMeansModel1.predict(Vectors.dense(r._5, r._6) ))}\n",
    "println(predictions1)\n",
    "val predDF1 = predictions1.toDF(\"issueName\", \"CLUSTER\")\n",
    "val t1 = allDF.join(predDF1, \"issueName\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User2,6,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User3,8,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User2,4,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source1,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User1,2,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User2,4,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task1,source2,User3,8,1,1,0]\n",
      "[Task2,source1,User2,4,1,2,0]\n",
      "[Task2,source1,User1,2,1,2,0]\n",
      "[Task2,source1,User1,1,1,2,0]\n",
      "[Task2,source1,User3,8,1,1,0]\n",
      "[Task2,source1,User2,5,1,2,0]\n",
      "[Task2,source1,User1,2,1,2,0]\n",
      "[Task2,source1,User1,3,1,2,0]\n",
      "[Task2,source2,User2,5,1,2,0]\n",
      "[Task2,source2,User3,6,1,2,0]\n",
      "[Task2,source2,User3,7,1,2,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User3,7,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,5,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User2,4,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source1,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User1,3,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User2,4,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task3,source2,User3,7,1,1,0]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User2,4,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User1,1,1,2,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User3,8,1,1,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User2,5,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,2,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source1,User1,3,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User2,5,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,6,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n",
      "[Task2,source2,User3,7,1,2,1]\n"
     ]
    }
   ],
   "source": [
    "t1.filter(\"CLUSTER = 0\").collect().foreach(println)\n",
    "t1.filter(\"CLUSTER = 1\").collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/org/plotly-scala/plotly-core_2.11/0.1.0/plotly-core_2.11-0.1.0.jar\n",
      "Finished download of plotly-core_2.11-0.1.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/org/plotly-scala/plotly-core_2.11/0.1.0/plotly-core_2.11-0.1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of plotly_2.10-0.1.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/co/theasi/plotly_2.10/0.1/plotly_2.10-0.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/co/theasi/plotly_2.11/0.1/plotly_2.11-0.1-sources.jar\n",
      "Finished download of plotly_2.11-0.1-sources.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/co/theasi/plotly_2.11/0.1/plotly_2.11-0.1-sources.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/co/theasi/plotly_2.11/0.1/plotly_2.11-0.1-javadoc.jar\n",
      "Finished download of plotly_2.11-0.1-javadoc.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/co/theasi/plotly_2.11/0.1/plotly_2.11-0.1-javadoc.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0-javadoc.jar\n",
      "Finished download of plotly-jupyter-scala_2.11-0.1.0-javadoc.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0-javadoc.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0-sources.jar\n",
      "Finished download of plotly-jupyter-scala_2.11-0.1.0-sources.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0-sources.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0.jar\n",
      "Finished download of plotly-jupyter-scala_2.11-0.1.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/org/plotly-scala/plotly-jupyter-scala_2.11/0.1.0/plotly-jupyter-scala_2.11-0.1.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached version of plotly_2.10-0.1.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar http://central.maven.org/maven2/co/theasi/plotly_2.10/0.1/plotly_2.10-0.1.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:25: error: not found: value ScatterOptions\n",
       "       val commonOptions = ScatterOptions().mode(ScatterMode.Marker).marker(MarkerOptions().size(12).lineWidth(1))\n",
       "                           ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import co.theasi.plotly\n",
    "\n",
    "val gdpAmerica = Vector(12779.379640000001, 3822.1370840000004, 9065.800825, 36319.235010000004,\n",
    "  13171.63885, 7006.580419, 9645.06142, 8948.102923, 6025.374752000001,\n",
    "  6873.262326000001, 5728.353514, 5186.050003, 1201.637154,\n",
    "  3548.3308460000003, 7320.880262000001, 11977.57496, 2749.320965,\n",
    "  9809.185636, 4172.838464, 7408.905561, 19328.70901, 18008.50924,\n",
    "  42951.65309, 10611.46299, 11415.805690000001)\n",
    "\n",
    "val lifeExpectancyAmerica = Vector(75.32, 65.554, 72.39, 80.653, 78.553, 72.889,\n",
    "  78.782, 78.273, 72.235, 74.994, 71.878, 70.259, 60.916, 70.198, 72.567,\n",
    "  76.195, 72.899, 75.537, 71.752, 71.421, 78.746, 69.819, 78.242, 76.384, 73.747)\n",
    "\n",
    "val labelAmerica = Vector(\n",
    "  \"Argentina\",\n",
    "  \"Bolivia\",\n",
    "  \"Brazil\",\n",
    "  \"Canada\",\n",
    "  \"Chile\",\n",
    "  \"Colombia\",\n",
    "  \"Costa Rica\",\n",
    "  \"Cuba\",\n",
    "  \"Dominican Republic\",\n",
    "  \"Ecuador\",\n",
    "  \"El Salvador\",\n",
    "  \"Guatemala\",\n",
    "  \"Haiti\",\n",
    "  \"Honduras\",\n",
    "  \"Jamaica\",\n",
    "  \"Mexico\",\n",
    "  \"Nicaragua\",\n",
    "  \"Panama\",\n",
    "  \"Paraguay\",\n",
    "  \"Peru\",\n",
    "  \"Puerto Rico\",\n",
    "  \"Trinidad and Tobago\",\n",
    "  \"United States\",\n",
    "  \"Uruguay\",\n",
    "  \"Venezuela\"\n",
    ")\n",
    "\n",
    "val gdpEurope = Vector(5937.029525999999, 36126.4927, 33692.60508, 7446.298803, 10680.79282,\n",
    "  14619.222719999998, 22833.30851, 35278.41874, 33207.0844, 30470.0167,\n",
    "  32170.37442, 27538.41188, 18008.94444, 36180.789189999996, 40675.99635,\n",
    "  28569.7197, 9253.896111, 36797.93332, 49357.19017, 15389.924680000002,\n",
    "  20509.64777, 10808.47561, 9786.534714, 18678.31435, 25768.25759,\n",
    "  28821.0637, 33859.74835, 37506.419069999996, 8458.276384, 33203.2612)\n",
    "\n",
    "val lifeExpectancyEurope = Vector(76.423, 79.829, 79.441, 74.852, 73.005, 75.748, 76.486,\n",
    "  78.332, 79.313, 80.657, 79.406, 79.483, 73.33800000000001, 81.757, 78.885, 80.546,\n",
    "  74.543, 79.762, 80.196, 75.563, 78.098, 72.476, 74.002, 74.663, 77.926,\n",
    "  80.941, 80.884, 81.70100000000001, 71.777, 79.425)\n",
    "\n",
    "val labelEurope = Vector(\n",
    "  \"Albania\",\n",
    "  \"Austria\",\n",
    "  \"Belgium\",\n",
    "  \"Bosnia and Herzegovina\",\n",
    "  \"Bulgaria\",\n",
    "  \"Croatia\",\n",
    "  \"Czech Republic\",\n",
    "  \"Denmark\",\n",
    "  \"Finland\",\n",
    "  \"France\",\n",
    "  \"Germany\",\n",
    "  \"Greece\",\n",
    "  \"Hungary\",\n",
    "  \"Iceland\",\n",
    "  \"Ireland\",\n",
    "  \"Italy\",\n",
    "  \"Montenegro\",\n",
    "  \"Netherlands\",\n",
    "  \"Norway\",\n",
    "  \"Poland\",\n",
    "  \"Portugal\",\n",
    "  \"Romania\",\n",
    "  \"Serbia\",\n",
    "  \"Slovak Republic\",\n",
    "  \"Slovenia\",\n",
    "  \"Spain\",\n",
    "  \"Sweden\",\n",
    "  \"Switzerland\",\n",
    "  \"Turkey\",\n",
    "  \"United Kingdom\"\n",
    ")\n",
    "\n",
    "// Options common to both traces\n",
    "val commonOptions = ScatterOptions().mode(ScatterMode.Marker).marker(MarkerOptions().size(12).lineWidth(1))\n",
    "\n",
    "// Options common to both axes\n",
    "val commonAxisOptions = AxisOptions().tickLength(5).gridWidth(2)\n",
    "\n",
    "val xAxisOptions = commonAxisOptions.title(\"GDP per capita (dollars)\").noZeroLine\n",
    "val yAxisOptions = commonAxisOptions.title(\"Life expectancy (years)\")\n",
    "\n",
    "// The plot itself\n",
    "val p = Plot().withScatter(gdpAmerica, lifeExpectancyAmerica,commonOptions.name(\"Americas\").text(labelAmerica)).withScatter(gdpEurope, lifeExpectancyEurope,commonOptions.name(\"Europe\").text(labelEurope)).xAxisOptions(xAxisOptions).yAxisOptions(yAxisOptions)\n",
    "//val p = Plot().withScatter(gdpAmerica, lifeExpectancyAmerica,commonOptions.name(\"Americas\").text(labelAmerica)).withScatter(gdpEurope, lifeExpectancyEurope,commonOptions.name(\"Europe\").text(labelEurope))\n",
    "val writer = FigureWriter()\n",
    "val figure = Figure().plot(p).title(\"Life Expectancy v. Per Capita GDP, 2007\")\n",
    "\n",
    "draw(figure, p, \"life-expectancy-per-GDP-2007\",writer.FileOptions(overwrite=true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}